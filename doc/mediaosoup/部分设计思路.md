## service概念介绍
- 信令服务器根据service对不同的服务子域进行划分，每个子域有两个重要的参数 servicekey  serviceid
- 集群搭建之除，会在配置文件中配置SuperService 
```
config.nuve.superserviceID = '5dbc11d889a1d0aca45ba5a7';
config.nuve.superserviceKey = '26891';
```
 同时会在mongodb中插入superservice信息
 ```
 mongo $dbURL --eval "db.services.insert({name: 'superService', key:<顶层服务key>, rooms: []})"
 ```
 ### 子域划分
 - 当一个开发者从平台申请服务时，我们调用NUVE的接口为他创建一个service,返回给他对应的serviceid和servicekey,
 后继该开发者在房间操作等行为时，都需要使用servieid和servierkey,服务器依据这两个参数进行鉴权
 - 同一个子域的开发者只能操作该子域下的资源，比如房间，用户等等 
 - 创建子域使用的superserviceid和superserverkey

 

## EA的分配策略
### 说明
- EA的管理中心是所有的EC，每个EC都维护了当前集群中的所有的EA的列表
- EA的分配时间点为EC上的Room创建，也就是当房间第一个用户进入时
- EA的分配策略分成两种情况 非级联模式 和级联模式
#### 非级联模式
- 在非级联模式，一个房间的所有用户都在一个EA的相同SFU上，
- 具体分配到哪个EA上，默认的策略是根据每个EA的房间数量，最少的优先分配
#### 级联模式
- 级联模式是为了应对 用户分布地域差异，可能会导致延迟较大的问题
- 在级联模式下，EC总是为用户分配一个网路距离最近的EA
- 级联模式下，每个用户所在的EA可能都是不一样的，但是每个EA只会为一个房间分配同一个SFU，
    也就是说如果一个两个用户分配到了相同的EA，那么他们肯定在同一个SFU上
- 房间级联模式的开启是在创建房间时传入参数eapolicy 设置房间是否开启 SFU级联
- EC作为网关，存储了客户端的地址信息，它将信息同步给EA，每个EA通过计算PING值，反馈到EC
### EA网络波动对服务的影响
#### 说明 
- 在实际的情况下，网络的波动，可能会造成EC对EA的保活检测超时，在真正把EA从EC的agents删除之前，EA可能会参与服务，
这种情况下被分配的EA实际可能已经失联，会发生很多未知的错误 
#### ROOM-BEST模式
- 在ROOM-BEST模式下，是根据每个EA的负载最小分配的，在计算时还需要考虑每个EA是否处于，断连容忍状态，处于这种状态的EA，不应该参与服务
#### TTL-BEST模式
- TTL-BEST模式由于会需要测试PING值，对于断连的EA本身就不会收到回复，自然不会参与服务

#### Client保持对EA状态的监听
- 由于在ROOM-BEST模式下，一个房间都属于一个EA上的一个Router,如果该EA失联，可能出现的情况是Client未主动断开和EC的连接，导致
EC上一直保存着该room实例，这样后继用户进入房间时，由于房间已经存在，就会继续使用该EA,必然会导致服务不可用
- 解决方案：
  EC中ecch实例负责管理EA，使用client对ecch注册监听事件
  ecch当要删除一个EA时抛出事件
  cient比对eaid和自己当前所在的eaid,如相同，则从EC端主动退出，关闭socket

## EC的分配策略
### 说明
- EC的管理中心是NUVE，EC在启动后到NUVE注册
- 当用户申请token时NUVE为用户分配一个EC，默认的分配策略是随机
- 同一个房间的用户一定会被分配到同一个EC上

## SFU的分配策略
### 说明
- 这里说的SFU指的是mediasoup的worker子进程，程序启动后会根据节点服务器的CPU数量启动对应数量的SFU，
    以实现对资源的最大化利用
- EA维护当前节点的SFU列表，当新的逻辑房间创建时,EC请求到EA为房间分配一个SFU，EA的策略是循环分配，保证每个SFU上的房间数量都是
    相同的，但不能保证负载相同

## worker进程为什么要根据核数去创建
### 说明
- mediasouo-worker子进程为单线程，在实际部署时EA由于对端口的需求量大，往往单独部署，
  为了对该机器资源的最大化利用，所以启动的worker子进程和CPU的数量相同

## EC<--->EA如何保证数据的同步 
### 说明 
- 这里说的同步，主要指的是 room、client 状态同步 
### room
- room在EC的创建时机是第一个用户请求进入房间时
- room在EA的创建时机是ec-room创建时，每个房间都需要关联的一个或者是多个EA，当创建房间时首先就会创建ea-room

- room在EC的消除时机是当最后一个用户退出时，
- room在EA的消除也是在最后一个用户退出时，EC在用户退出时会广播消息，通知EA删除对应的用户，当发现房间内用户为空，则删除房间

### client
- client在EC的创建时机为token事件处理后
- client在EA的创建时机为处理用户的 getRouterRtpCapabilities 事件


## 限流
### NUVE限流
- 所有的客户端在连接进入系统的第一步就是到NUVE获取token，所谓NUVE的HTTP接口是作为第一级限流
- NUVE的限流分为两部分，全局的QPS 和针对单个IP地址QPS限制
#### 全局QPS
- 全局QPS限制整个NUVE集群对外的并发数量，默认数值为1000，超过10000部分直接回复错误
- 全局QPS可以开启队列，当开启队列时，对于超出1000的部分入队列
#### 单个用户QPS
- 单个用户QPS限制单个IP地址在单位时间内的请求次数，超过直接回复错误

### EC限流
- EC作为网关，针对EC的限流时本地的，也就是我们只限制单个EC的接入QPS,因为用户来连接EC时NUVE已经将该用户和该EC绑定，
  为了避免EC之间的相互影响，每个EC的QPS计数都是存储在本地

### 语音消息
- 语音消息在不同游戏之间如何进行隔离
语音消息SDK在接入时有账户的概念，不同的游戏可以使用不同的账户，这样数据/以及将来计费就都有了区分的依据


## k8s环境中的无缝滚动升级
### k8s中升级模式 
- 目前k8s中支持蓝绿升级和滚动更新，理论上蓝绿更新适应于版本之间存在不兼容的情况，会造成服务的不稳定
  滚动更新能够最大程度的保证服务的可用性，同时对资源的要求也相对较小，mediasoup信令服务器我们采用滚动更新的方式
- 不管是滚动更新还是蓝绿更新，本质上对无状态的应用更加友好，针对有状态的应用，很难做到无缝的升级/更新，k8s的RC(副本管理器)在把旧版本
  的 pod杀死时并不会考虑应用本身的一些状态，比如网络连接/数据落地等等
- 滚动更新配置
```
strategy:
rollingUpdate:
  maxSurge: 25%    
  maxUnavailable: 25%
type: RollingUpdate

maxSurge 最大溢出数量，表示在更新时，pod可以最多溢出多少，可以配置数字或者是百分比
		该值设置的越大，更新速度越快，但是资源占用会比较大
maxUnavailable 最大不可用数量，表示更新时，最多有多少pod处在不可用状态，可以配置数字或者是百分比 
		该值设置的越大，更新速度越快，但是服务会更不稳定
``` 


### 滚动更新存在的问题 
- 针对EC和EA如果直接杀死POD,必定会造成和他们连接的Client出现断线等异常现象，影响用户体验 
- EA和EC本质上并不是无状态的应用,当在更新时，我们希望当旧版本的pod用户都推出后，才把他们删除掉

### 设计方案 
- 使用k8s的PreStop，在pod接受到停止实践时触发，PreStop的特性为阻塞调用，只要PreStop对应的命令不返回，kill-pod行为就不会发生
  针对EC 在prestop脚本中给EC的进程发送SIGSTERM信号，EC接收信号后到NUVE设置自身状态为0，则EC后继不会参与新的房间的分配流程 

  针对EA 在prestop脚本中给EA的进程发送SIGSTERM信号，EA接收信号后更新自己的状态为0,
    在ROOM-BEST模式下，EC在分配EA时会直接把状态为0的EA过滤掉，另外处于0状态的EA，针对广播发送的
    在TTL-BETST模式下，EC在发送pingcost请求时也会把状态为0的EA过滤掉

- 另外设置 最大优雅关闭时长(terminationGracePeriodSeconds)为30分钟，如果30分钟后旧版本上还有连接，则强制删除pod
- 另外为了保证整个集群的容纳量，需要设置maxSurge为100%,maxSurge意为pod最大溢出数量，因为再使用prestop后，可能再更新时所有的EC上都有连接
  这样旧版本的pod都没有再第一时间销毁，如果maxSurge小于100%，则最严重的情况时30分钟内，没有一个可用的EC，这将是灾难性的

- 通过上面几个层面 可以实现无缝的滚动更新, 
 





